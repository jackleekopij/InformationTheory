# InformationTheory
A repo for information theory exploration. 

Ideally will serve as a repo for code relating to study of ["Elements of Information Theory"](http://www.cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf)


## Entropy (statistics) 
Entropy can be seen as the amount of uncertainty within a random variable. The higher the entropy the more uncertainty there is about a random variable. *Entropy* can be calculated using the following:
<a href="https://www.codecogs.com/eqnedit.php?latex=Entropy&space;=&space;\sum^n_{i=1}&space;p(x_i)&space;*&space;log_2(p(x_i))" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Entropy&space;=&space;\sum^n_{i=1}&space;p(x_i)&space;*&space;log_2(p(x_i))" title="Entropy = \sum^n_{i=1} p(x_i) * log_2(p(x_i))" /></a>
